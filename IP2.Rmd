---
title: "Unsupervised learning"
author: "Karen Mwaura"
date: "1/29/2022"
output: html_document
---

##UNSUPERVISED LEARNING WITH R

##Define the question
```{r}

#A brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year on a Russian brand sold in retail stores. More specifically, they would like to learn the characteristics of customer groups.

```

##Metric of success
```{r}

#This project will be successful when we perform clustering enabling gain of insights from the analysis and visualizations.

```

##Context
```{r}
#Kira Plastinina; Russian fashion Designer owns a brand Kira plastinina. The brand was sold through a now defunct chain of eponymous retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines and Armenia. 

```

##Experimental design taken
```{r}
#The experimental design taken for this project includes:

  #*Problem Definition
  #*Data Sourcing
  #*Check the Data
  #*Perform Data Cleaning
  #*Perform Exploratory Data Analysis  (Univariate, Bivariate & Multivariate)
  #*Implement the Solution
  #*Challenge the Solution
  #*Follow up Questions
  #*
  
```

##Data understanding
```{r}

#The dataset consists of 10 numerical and 8 categorical attributes. "Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another. 
#The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 
#The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 
#The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.
#The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 
#The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. 
#The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.


```

##appropriateness of the available data
```{r}

#The data in question is accurate and useful to accomplish the metrics of success.

```

##Load the dataset
```{r}

#install.packages("tidyverse")
library(tidyverse)
library(readr)
df <- read_csv("C:/Users/user/Downloads/online_shoppers_intention.csv")

head(df)
```

#Get the shape of the dataset
```{r}

dim(df)

```
#Check for duplicated values
```{r}

duplicated_rows <- df[duplicated(df),]
duplicated_rows 

```


#Get the dtypes for the columns
```{r}

sapply(df, class)

```

#Check for statistical summary values
```{r}

summary(df)


```

##DATA CLEANING

#Checking for missing values
```{r}

colSums(is.na(df))

```

##Dealing with missing values
```{r}
#Dropping the missing values

df<- na.omit(df)
df



```

#Confirming if all values are dropped
```{r}

colSums(is.na(df))

```

##Dropping duplicates
```{r}

df <- df[!duplicated(df), ]
df

```

##Confirming duplicates are dropped
```{r}

sum(duplicated(df))

```

```{r}

colnames(df)
```

##CHECK FOR OUTLIERS
```{r}
#Plot for administartive

install.packages("tidyverse")
library(tidyverse)
library(readr)
```

```{r}
boxplot(df$Administrative,
  ylab = "Administrative"
)

```

```{r}

#Plot for Informational

boxplot(df$Informational,
  ylab = "Informational"
)

```

```{r}
#Plot for ProductRelated

boxplot(df$ProductRelated,
  ylab = "ProductRelated"
)

```

```{r}
#Plot for ProductRelated_Duration

boxplot(df$ProductRelated_Duration,
  ylab = "ProductRelated_Duration"
)

```

```{r}
#Plot for BounceRates

boxplot(df$BounceRates,
  ylab = "BounceRates"
)

```

```{r}
#Plottign for ExitRates
boxplot(df$ExitRates,
        ylab= "ExitRates"
)

```

```{r}
#Plotting for PageValues

boxplot(df$PageValues,
        ylab= "PageValues" )

```

##Univariate Analysis

##Graphical Illustration 
```{r}

hist(df$Administrative, col = "red", border = "black", density=30)


```

```{r}
hist(df$Informational, col = "red", border = "black", density=30)

```

```{r}

hist(df$ProductRelated, col = "red", border = "black", density=30)

```

```{r}

hist(df$BounceRates, col = "red", border = "black", density=30)

```

```{r}

hist(df$ExitRates, col = "red", border = "black", density=30)


```

```{r}

hist(df$PageValues, col = "red", border = "black", density=30)

```

```{r}

hist(df$SpecialDay, col = "red", border = "black", density=30)

```

##BIVARIATE AND MULTIVARIATE ANALYSIS

#Correlation and covariance
```{r}
#Get the covariance

ProductRelated<- df$ProductRelated

Informational <- df$Informational

cov(ProductRelated, Informational)

```

```{r}

#Get the correlation
cor(ProductRelated, Informational)

```

```{r}

#Get the covariance
Administrative <- df$Administrative
Revenue <- df$Revenue

Informational <- df$Informational

cov(Revenue, Informational)

```

```{r}
#Get the correlation
cor(Revenue, Informational)

```

```{r}

cor(Revenue, ProductRelated)

```

```{r}

cor(Revenue, Administrative)

```


```{r}

#corrplot

cor(df[, unlist(lapply(df, is.numeric))])

```

#BIVARIATE ANALYSIS
```{r}
#Plot for weekend vs Informational Duration

plot(df$Weekend, df$Informational_Duration, xlab="Weekend", ylab="Information Duration", main= "Weekend vs Information Duration")


```

```{r}

#Plot for weekend vs Informational Duration

plot(df$Weekend, df$ProductRelated_Duration, xlab="Weekend", ylab="ProductRelated Duration", main= "Weekend vs ProductRelated Duration")

```


```{r}
#Plot for SpecialDay vs ProductRelated Duration

plot(df$SpecialDay, df$ProductRelated_Duration, xlab="SpecialDay", ylab="ProductRelated Duration", main= "SpecialDay vs ProductRelated Duration")

```


```{r}

#Plot for SpecialDay vs Informational Duration

plot(df$SpecialDay, df$Informational_Duration, xlab="SpecialDay", ylab="ProductRelated Duration", main= "SpecialDay vs ProductRelated Duration")

```


```{r}

#Plot for special day and administrative duration

plot(df$SpecialDay, df$Administrative_Duration, xlab="SpecialDay", ylab="Administrative Duration", main= "Special Day vs Administrative Duration")


```

```{r}
#Plot for weekend and exit rates

plot(df$Weekend, df$ExitRates, xlab="x", ylab="y", main= "x vs y")

```

```{r}
#Plot for weekend and Page values

plot(df$Weekend, df$PageValues, xlab="Weekend", ylab="PageValue", main= "Weekend vs Page Value")

```


```{r}
#Plot fro product and product duration

plot(df$ProductRelated, df$ProductRelated_Duration, xlab="Product Related", ylab="Product Related Duration", main= "Product Related vs Product Related Duration")

```


```{r}
#Plot for administrative and administrative Duration
plot(df$Administrative, df$Administrative_Duration, xlab="Administartive", ylab="Administartive Duration", main= "Administartive vs Administartive Related Duration")


```

```{r}

#Plot for Informational and Informational Duration
plot(df$Informational, df$Informational_Duration, xlab="Informational", ylab="Informational Duration", main= "Informational vs Informational Duration")

```


#One Hot Encoding
```{r}
#Import necessary library

library(caret)

dummy <- dummyVars(" ~ .", data=df)
newdata <- data.frame(predict(dummy, newdata = df)) 

```

```{r}

#Check for datatypes

sapply(newdata, class)

```

#K-Means Clustering
```{r}
# Normalizing the dataset
newdata1<- newdata[, c(1, 2, 3, 4, 5, 6 ,7,8,9,10,11,12,13,14,15,16,17)]

head(newdata)
normalize <- function(x){
  return ((x-min(x)) / (max(x)-min(x)))
}

```

```{r}
result<- kmeans(newdata,5) 

result$size 

```

```{r}
# Getting the value of cluster center datapoint value

result$centers 

```


```{r}
#Getting the cluster vector that shows the cluster where each record falls

result$cluster

```


```{r}
# Visualizing the  clustering results

par(mfrow = c(1,2), mar = c(5,4,2,2))

```

```{r}
#Plotting

plot(newdata[,1:4], col = result$cluster) 

```

```{r}
plot(newdata[,5:7], col = result$cluster)
```

#Hierarchical analysis
```{r}
# Installing the package
install.packages("dplyr")

# Loading package
library(dplyr)


#Compute some descriptive statistics

desc_stats <- data.frame(
  Min = apply(newdata, 2, min),    # minimum
  Med = apply(newdata, 2, median), # median
  Mean = apply(newdata, 2, mean),  # mean
  SD = apply(newdata, 2, sd),      # Standard deviation
  Max = apply(newdata, 2, max)     # Maximum
)
desc_stats <- round(desc_stats, 1)
head(desc_stats)

```

```{r}

# we start by scaling the data using the R function scale()

newdata <- scale(newdata)
head(newdata)

```


```{r}

d<-dist(newdata, method = "euclidean")

# Compute hierarchical clustering
res.hc <- hclust(d, method = "ward.D2" )

#plot the obtained dendrogram
plot(res.hc, cex = 0.5, hang = 2)

```


#Conclusions and recommendations

```{r}
#Several columns;Administartive, Informational had outliers. The outliers were not dropped.Majority of the visited sites during the weekend is the information site.
#Most of the special days don't have a lot of people assessing the sites ie;Informational,Administartive,Product Related. Majority of people tend to visit the product related sites.

```

#Follow up questions
```{r}

#Do we have the right data? The data given was enough.

# Was the data sufficient?

#

```